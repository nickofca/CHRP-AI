{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Script for CHRP-AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath to data to be cleaned\n",
    "filepath = '/Users/ethanweiss/Desktop/Class documents/Spring 2020/Senior Design/Chiller Tons/Load_Data_Full.csv'\n",
    "# read data from csv into pandas dataframe\n",
    "data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary for unreliable indecies\n",
    "unreliable_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get index of UNRELIABLE points\n",
    "##### Store indecies of unreliable data points in dictionary where keys are column indecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indecies for all \"eDNA Status as String\" columns\n",
    "status_cols = [i for i in range(len(data.columns)) if i%3 == 2]\n",
    "# chiller_cols = [i for i in range(len(data.columns)) if i%3 == 0]\n",
    "# chiller_col_labels = [data.columns[x] for x in chiller_cols]\n",
    "\n",
    "# Loop through all status columns \n",
    "for j in status_cols:\n",
    "    unr_index = [] # reset unreliable index list to empty\n",
    "    for i in range(len(data)): # loop through all rows of data\n",
    "        if data.iloc[i,j] == 'UNRELIABLE': # check if unreliable\n",
    "            unr_index.append(i) # if unreliable, add index to list\n",
    "    unreliable_dict[j] = unr_index # assign list of unreliable indecies to column index key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "# Count number of UNRELIABLE points\n",
    "total = 0\n",
    "for x in unreliable_dict.keys():\n",
    "    total += len(unreliable_dict[x])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Use Linear Interpolation to get values for previously UNRELIABLE data points**\n",
    "Assuming that UNRELIABLE data points occur in bunches, we want to linearly interpolate using the boundary values of Reliable data points. The \"before bound\" will be the value of the Reliable data point which occured right before the bunch of UNRELIABLE data points. The \"after bound\" will be the value of the Reliable data point which occurs right after the bunch of UNRELIABLE data points.\n",
    "\n",
    "Process for Linear Interpolation: <br>\n",
    "    1) Find \"before index\" --> Index of previous Reliable data point <br>\n",
    "    2) Find \"before bound\" --> Value of previous Reliable data point <br>\n",
    "    3) Find \"after index\" --> Index of next Reliable data point <br>\n",
    "    4) Find \"after bound\" --> Value of next Reliable data point <br>\n",
    "    5) Calculate slope --> $slope = \\frac{a_{bound}-b_{bound}}{a_{index}-b_{index}}$ <br>\n",
    "    6) Calculate new value --> $b_{bound} + slope * (c_{index} - b_{index})$ <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all column indecies with unreliable data\n",
    "for x in unreliable_dict.keys():\n",
    "    # loop through all unreliable values\n",
    "    for i in unreliable_dict[x]:\n",
    "        # loop through all indecies before unreliable point\n",
    "        for j in range(1,i):\n",
    "            if data.iloc[i-j,x] != 'UNRELIABLE': # check for unreliable point\n",
    "                # IF NOT UNRELIABLE: \n",
    "                before_bound = data.iloc[i-j,x-1] # set before bound value\n",
    "                before_index = i-j # set before index value\n",
    "                break # break loop once before bound is found\n",
    "        # loop through all indecies after unreliable point\n",
    "        for j in range(1,len(data) - i): \n",
    "            if data.iloc[i+j,x] != 'UNRELIABLE': # check for unreliable point\n",
    "                # IF NOT UNRELIABLE:\n",
    "                after_bound = data.iloc[i+j,x-1] # set after bound value\n",
    "                after_index = i+j # set after index value\n",
    "                break # break loop once after bound is found\n",
    "       \n",
    "        # Linear Interpolation to substitute for UNRELIABLE values\n",
    "        slope = (after_bound - before_bound)/(after_index - before_index)\n",
    "        data.iloc[i,x-1] = before_bound + slope * (i - before_index)\n",
    "\n",
    "# Replace 'UNRELIABLE' tags with 'LI' tags\n",
    "for x in unreliable_dict.keys():\n",
    "    for i in unreliable_dict[x]:\n",
    "        data.iloc[i,x] = 'LI'\n",
    "        \n",
    "        # DEBUG\n",
    "#         if (x == 32 and i == 354):\n",
    "#             print('before bound: {0}'.format(before_bound))\n",
    "#             print('before index: {0}'.format(before_index))\n",
    "#             print('after bound: {0}'.format(after_bound))\n",
    "#             print('after index: {0}'.format(after_index))\n",
    "#             print('slope: {0}'.format(slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "# Count number of LI tags\n",
    "total = 0\n",
    "for j in status_cols:\n",
    "    for i in range(len(data)):\n",
    "        if data.iloc[i,j] == 'LI':\n",
    "            total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset with 'LI' tags as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/ethanweiss/Desktop/Class documents/Spring 2020/Senior Design/Chiller Tons/Load_Data_Full_LItags.csv'\n",
    "data.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only keep relevant columns and rename accordingly\n",
    "Keep only the first Date/time column and all Values columns. Rename Values columns according to chiller name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chiller names\n",
    "chiller_cols = [i for i in range(len(data.columns)) if i%3 == 0]\n",
    "chiller_cols = [data.columns[x] for x in chiller_cols]\n",
    "# Get value columns to keep\n",
    "value_cols = [i for i in range(len(data.columns)) if i%3 == 1]\n",
    "value_cols = [data.columns[x] for x in value_cols]\n",
    "# Compile columns to keep in dataframe\n",
    "data.rename({'AHSC_CHL01_TONS':'Date/Time'},axis = 1,inplace = True)\n",
    "keep_cols = ['Date/Time'] + value_cols\n",
    "# Create Dictionary for guide to rename columns with appropriate chiller names\n",
    "rename_dict = {}\n",
    "for i in range(len(keep_cols[1:])):\n",
    "    rename_dict[keep_cols[i]] = chiller_cols[i]\n",
    "# Assign new column names (appropriate chiller names)\n",
    "rel_data.rename(rename_dict,axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CSV of relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/ethanweiss/Desktop/Class documents/Spring 2020/Senior Design/Chiller Tons/Load_Data_Full_ChillerValuesOnly.csv'\n",
    "rel_data.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>AHSC_CHL01_TONS</th>\n",
       "      <th>AHSC_CHL02_TONS</th>\n",
       "      <th>AHSC_CHL03_TONS</th>\n",
       "      <th>CHRP_CHL08_TONS</th>\n",
       "      <th>CHRP_CHL09_TONS</th>\n",
       "      <th>CHRP_CHL06_TONS</th>\n",
       "      <th>CHRP_CHL07_TONS</th>\n",
       "      <th>CHRP_CHL10_TONS</th>\n",
       "      <th>CHRP_CHL11_TONS</th>\n",
       "      <th>...</th>\n",
       "      <th>CRB_CHL07_TONS</th>\n",
       "      <th>CRB_CHL08_TONS</th>\n",
       "      <th>CRB_CHL09_TONS</th>\n",
       "      <th>CRB_CHL10_TONS</th>\n",
       "      <th>CRB_CHL01B_TONS</th>\n",
       "      <th>AHSC_CHL04_TONS</th>\n",
       "      <th>AHSC_CHL07_TONS</th>\n",
       "      <th>AHSC_CHL08_TONS</th>\n",
       "      <th>CRB_CHL02B_TONS</th>\n",
       "      <th>CRB_CHL03B_TONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-12 00:00:00</td>\n",
       "      <td>1208.309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2181.195</td>\n",
       "      <td>...</td>\n",
       "      <td>893.11150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-12 00:02:00</td>\n",
       "      <td>1211.706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2176.634</td>\n",
       "      <td>...</td>\n",
       "      <td>883.93870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1057.453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-12 00:04:00</td>\n",
       "      <td>1212.154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2162.145</td>\n",
       "      <td>...</td>\n",
       "      <td>886.16180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1058.788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-12 00:06:00</td>\n",
       "      <td>1208.656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2163.059</td>\n",
       "      <td>...</td>\n",
       "      <td>881.93895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1060.142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-12 00:08:00</td>\n",
       "      <td>1211.696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2163.059</td>\n",
       "      <td>...</td>\n",
       "      <td>877.71610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1062.337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date/Time  AHSC_CHL01_TONS  AHSC_CHL02_TONS  AHSC_CHL03_TONS  \\\n",
       "0  2019-02-12 00:00:00         1208.309              0.0              0.0   \n",
       "1  2019-02-12 00:02:00         1211.706              0.0              0.0   \n",
       "2  2019-02-12 00:04:00         1212.154              0.0              0.0   \n",
       "3  2019-02-12 00:06:00         1208.656              0.0              0.0   \n",
       "4  2019-02-12 00:08:00         1211.696              0.0              0.0   \n",
       "\n",
       "   CHRP_CHL08_TONS  CHRP_CHL09_TONS  CHRP_CHL06_TONS  CHRP_CHL07_TONS  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   CHRP_CHL10_TONS  CHRP_CHL11_TONS  ...  CRB_CHL07_TONS  CRB_CHL08_TONS  \\\n",
       "0              0.0         2181.195  ...       893.11150             0.0   \n",
       "1              0.0         2176.634  ...       883.93870             0.0   \n",
       "2              0.0         2162.145  ...       886.16180             0.0   \n",
       "3              0.0         2163.059  ...       881.93895             0.0   \n",
       "4              0.0         2163.059  ...       877.71610             0.0   \n",
       "\n",
       "   CRB_CHL09_TONS  CRB_CHL10_TONS  CRB_CHL01B_TONS  AHSC_CHL04_TONS  \\\n",
       "0             0.0             0.0              0.0         1047.702   \n",
       "1             0.0             0.0              0.0         1057.453   \n",
       "2             0.0             0.0              0.0         1058.788   \n",
       "3             0.0             0.0              0.0         1060.142   \n",
       "4             0.0             0.0              0.0         1062.337   \n",
       "\n",
       "   AHSC_CHL07_TONS  AHSC_CHL08_TONS  CRB_CHL02B_TONS  CRB_CHL03B_TONS  \n",
       "0              0.0              0.0              0.0              0.0  \n",
       "1              0.0              0.0              0.0              0.0  \n",
       "2              0.0              0.0              0.0              0.0  \n",
       "3              0.0              0.0              0.0              0.0  \n",
       "4              0.0              0.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Outliers\n",
    "Use 1 hour interval (15 points before and 15 points after current point)\n",
    "\n",
    "For points with only N points before (w/ N < 15), use N points before and 30-N points after.<br>\n",
    "For points with only N points after (w/ N < 15), use N points after and 30-N points before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_cols = []\n",
    "for x in rel_data.columns[1:]:\n",
    "    outlier_col = [0 for i in range(len(rel_data))]\n",
    "    for i in range(len(rel_data)):\n",
    "        if i < 15:\n",
    "            window = rel_data.loc[0:29,x]\n",
    "            q1 = window.quantile(0.25)\n",
    "            q3 = window.quantile(0.75)\n",
    "            iqr = abs(q3 - q1)\n",
    "            if ((rel_data.loc[i,x] < q1 - 1.5 * iqr) or (rel_data.loc[i,x] > q3 + 1.5 * iqr)):\n",
    "                outlier_col[i] = 1\n",
    "        elif i > len(rel_data) - 15:\n",
    "            window = rel_data.loc[len(rel_data) - 30:len(rel_data) - 1,x]\n",
    "            q1 = window.quantile(0.25)\n",
    "            q3 = window.quantile(0.75)\n",
    "            iqr = abs(q3 - q1)\n",
    "            if ((rel_data.loc[i,x] < q1 - 1.5 * iqr) or (rel_data.loc[i,x] > q3 + 1.5 * iqr)):\n",
    "                outlier_col[i] = 1\n",
    "        else:\n",
    "            window = rel_data.loc[i-15:i+14,x]\n",
    "            q1 = window.quantile(0.25)\n",
    "            q3 = window.quantile(0.75)\n",
    "            iqr = abs(q3 - q1)\n",
    "            if ((rel_data.loc[i,x] < q1 - 1.5 * iqr) or (rel_data.loc[i,x] > q3 + 1.5 * iqr)):\n",
    "                outlier_col[i] = 1\n",
    "    outlier_cols.append(outlier_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date/Time', 'AHSC_CHL01_TONS', 'AHSC_CHL02_TONS', 'AHSC_CHL03_TONS',\n",
       "       'CHRP_CHL08_TONS', 'CHRP_CHL09_TONS', 'CHRP_CHL06_TONS',\n",
       "       'CHRP_CHL07_TONS', 'CHRP_CHL10_TONS', 'CHRP_CHL11_TONS',\n",
       "       'CHRP_CHL12_TONS', 'CRB_CHL05_TONS', 'CRB_CHL06_TONS', 'CRB_CHL07_TONS',\n",
       "       'CRB_CHL08_TONS', 'CRB_CHL09_TONS', 'CRB_CHL10_TONS', 'CRB_CHL01B_TONS',\n",
       "       'AHSC_CHL04_TONS', 'AHSC_CHL07_TONS', 'AHSC_CHL08_TONS',\n",
       "       'CRB_CHL02B_TONS', 'CRB_CHL03B_TONS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
